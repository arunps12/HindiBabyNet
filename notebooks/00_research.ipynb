{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3f07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python3\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03885ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce RTX 2080 Ti')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc55c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/arunps/Projects/HindiBabyNet/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import webrtcvad\n",
    "import torch\n",
    "\n",
    "from pyannote.audio import Pipeline, Model\n",
    "from pyannote.audio import Inference\n",
    "from pyannote.core import Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e307ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1739701628.WAV 16000 1 2.0364166666666668 hours\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "participant_id = \"ABAN141223\"\n",
    "session_date   = \"20250216\"\n",
    "\n",
    "session_dir = Path(\"/scratch/users/arunps/hindibabynet/audio_raw/ABAN141223/20250216\")\n",
    "wav_files = sorted(session_dir.glob(\"*.WAV\")) + sorted(session_dir.glob(\"*.wav\"))\n",
    "wav_path = Path(wav_files[1]) \n",
    "info = sf.info(str(wav_path))\n",
    "print(wav_path.name, info.samplerate, info.channels, info.duration/3600, \"hours\") \n",
    "recording_id = wav_path.stem\n",
    "# diarization bounds \n",
    "MIN_SPEAKERS = 2\n",
    "MAX_SPEAKERS = 4\n",
    "\n",
    "# chunking\n",
    "CHUNK_SEC = 15 * 60     # 15 min\n",
    "OVERLAP_SEC = 10        # small overlap to avoid cutting speech\n",
    "\n",
    "# VAD params \n",
    "VAD_AGGR = 2\n",
    "VAD_FRAME_MS = 30\n",
    "VAD_MIN_REGION_MS = 300\n",
    "\n",
    "# intersection / post-filter\n",
    "MIN_KEEP_SEC = 0.20     # drop tiny fragments after intersection\n",
    "\n",
    "# speaker embedding / global clustering\n",
    "EMB_MODEL_ID = \"pyannote/embedding\"     #  embedding checkpoint\n",
    "MIN_EMB_SEG_SEC = 1.0                  # ignore too-short segments for embeddings\n",
    "MIN_SPK_TOTAL_SEC_FOR_CENTROID = 10.0  # need enough speech to build a stable centroid\n",
    "COS_SIM_MERGE_THRESHOLD = 0.78         # threshold for merging speakers based on cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4542cd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>session_date</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>path</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>channels</th>\n",
       "      <th>size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739683525</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>17940.02</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>574081152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>7331.10</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>234595712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id session_date recording_id  \\\n",
       "0     ABAN141223     20250216   1739683525   \n",
       "1     ABAN141223     20250216   1739701628   \n",
       "\n",
       "                                                path  duration_sec  \\\n",
       "0  /scratch/users/arunps/hindibabynet/audio_raw/A...      17940.02   \n",
       "1  /scratch/users/arunps/hindibabynet/audio_raw/A...       7331.10   \n",
       "\n",
       "   sample_rate  channels  size_bytes  \n",
       "0        16000         1   574081152  \n",
       "1        16000         1   234595712  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create recordings DataFrame\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for p in wav_files:\n",
    "    info = sf.info(str(p))\n",
    "    rows.append({\n",
    "        \"participant_id\": \"ABAN141223\",\n",
    "        \"session_date\": \"20250216\",\n",
    "        \"recording_id\": p.stem,\n",
    "        \"path\": str(p),\n",
    "        \"duration_sec\": float(info.duration),\n",
    "        \"sample_rate\": int(info.samplerate),\n",
    "        \"channels\": int(info.channels),\n",
    "        \"size_bytes\": p.stat().st_size,\n",
    "    })\n",
    "\n",
    "recordings = pd.DataFrame(rows)\n",
    "recordings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "299c38af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN loaded\n"
     ]
    }
   ],
   "source": [
    "# Load HF_TOKEN from .env\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "assert os.getenv(\"HF_TOKEN\") is not None, \"HF_TOKEN not loaded\"\n",
    "print(\"HF_TOKEN loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "163c17f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0020585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable pyannote notebook mode\n",
    "import os\n",
    "os.environ[\"PYANNOTE_DISABLE_NOTEBOOK\"] = \"1\"\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18e44d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hugging Face cache to scratch space\n",
    "import os\n",
    "\n",
    "scratch_cache = f\"/scratch/users/{os.environ['USER']}/.cache/huggingface\"\n",
    "os.environ[\"HF_HOME\"] = scratch_cache\n",
    "os.environ[\"HF_HUB_CACHE\"] = f\"{scratch_cache}/hub\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = f\"{scratch_cache}/transformers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a74406e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/arunps/Projects/HindiBabyNet/.venv/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:73: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diarization pipeline loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "# Load diarization pipeline\n",
    "HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=HF_TOKEN\n",
    ")\n",
    "pipeline.to(device)\n",
    "\n",
    "print(\"Diarization pipeline loaded on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45f3183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/arunps/Projects/HindiBabyNet/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.6.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "/itf-fi-ml/home/arunps/Projects/HindiBabyNet/.venv/lib/python3.10/site-packages/pyannote/audio/core/model.py:692: UserWarning: Model has been trained with a task-dependent loss function. Set 'strict' to False to load the model without its loss function and prevent this warning from appearing. \n",
      "  warnings.warn(msg)\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.6.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.5.1+cu124. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.5.1+cu124. Bad things might happen unless you revert torch to 1.x.\n",
      "Embedding model loaded on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/arunps/Projects/HindiBabyNet/.venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:197: Found keys that are not in the model state dict but in the checkpoint: ['loss_func.W']\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "emb_model = Model.from_pretrained(EMB_MODEL_ID, use_auth_token=HF_TOKEN)\n",
    "emb_infer = Inference(emb_model, window=\"whole\")  # one embedding per segment\n",
    "emb_infer.to(device)\n",
    "\n",
    "print(\"Embedding model loaded on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff02ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions \n",
    "def make_chunks(duration_sec: float, chunk_sec: float, overlap_sec: float):\n",
    "    \"\"\"Yield (chunk_id, chunk_start, chunk_end) with overlap.\"\"\"\n",
    "    step = chunk_sec - overlap_sec\n",
    "    assert step > 0, \"chunk_sec must be > overlap_sec\"\n",
    "\n",
    "    t = 0.0\n",
    "    chunk_id = 0\n",
    "    while t < duration_sec:\n",
    "        s = t\n",
    "        e = min(t + chunk_sec, duration_sec)\n",
    "        yield chunk_id, s, e\n",
    "        if e >= duration_sec:\n",
    "            break\n",
    "        t += step\n",
    "        chunk_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e807032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: streaming WebRTC VAD on FULL AUDIO (no full-file load)\n",
    "# Returns sorted speech intervals [(start_sec, end_sec), ...]\n",
    "def webrtc_vad_regions_streaming(\n",
    "    path: Path,\n",
    "    aggressiveness: int = 2,\n",
    "    frame_ms: int = 30,\n",
    "    min_region_ms: int = 300,\n",
    "):\n",
    "    vad = webrtcvad.Vad(aggressiveness)\n",
    "    info = sf.info(str(path))\n",
    "    sr = info.samplerate\n",
    "    ch = info.channels\n",
    "\n",
    "    if sr not in (8000, 16000, 32000, 48000):\n",
    "        raise ValueError(f\"webrtcvad needs sr in (8k,16k,32k,48k). got: {sr}\")\n",
    "\n",
    "    frame_len = int(sr * frame_ms / 1000)\n",
    "\n",
    "    speech_flags = []\n",
    "    with sf.SoundFile(str(path), mode=\"r\") as f:\n",
    "        while True:\n",
    "            frame = f.read(frames=frame_len, dtype=\"int16\", always_2d=True)\n",
    "            if frame.size == 0 or len(frame) < frame_len:\n",
    "                break\n",
    "            mono = frame[:, 0]  # take ch0\n",
    "            speech_flags.append(vad.is_speech(mono.tobytes(), sr))\n",
    "\n",
    "    # merge consecutive true flags to regions in frames\n",
    "    regions = []\n",
    "    in_speech = False\n",
    "    start_i = 0\n",
    "    for i, is_speech in enumerate(speech_flags):\n",
    "        if is_speech and not in_speech:\n",
    "            in_speech = True\n",
    "            start_i = i\n",
    "        elif (not is_speech) and in_speech:\n",
    "            in_speech = False\n",
    "            regions.append((start_i, i))\n",
    "    if in_speech:\n",
    "        regions.append((start_i, len(speech_flags)))\n",
    "\n",
    "    # convert to seconds and filter\n",
    "    out = []\n",
    "    for s_i, e_i in regions:\n",
    "        s = (s_i * frame_len) / sr\n",
    "        e = (e_i * frame_len) / sr\n",
    "        if (e - s) * 1000 >= min_region_ms:\n",
    "            out.append((float(s), float(e)))\n",
    "\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "feb53dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Helper: interval intersection (two-pointer, sorted lists)\n",
    "# Inputs:\n",
    "#   diar_df: columns [start_sec, end_sec, ...] sorted\n",
    "#   vad_intervals: list of (start_sec, end_sec) sorted\n",
    "# Output:\n",
    "#   speech-only rows with same metadata + speaker columns\n",
    "# --------------------------\n",
    "def intersect_diar_with_vad(diar_df: pd.DataFrame, vad_intervals, min_keep_sec: float = 0.0):\n",
    "    diar_arr = diar_df[[\"start_sec\", \"end_sec\", \"speaker_id_global\"]].to_numpy()\n",
    "    vad_arr = np.array(vad_intervals, dtype=float)\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    rows = []\n",
    "\n",
    "    def intersect(a_s, a_e, b_s, b_e):\n",
    "        s = max(a_s, b_s)\n",
    "        e = min(a_e, b_e)\n",
    "        return (s, e) if s < e else None\n",
    "\n",
    "    while i < len(diar_arr) and j < len(vad_arr):\n",
    "        ds, de, spk = diar_arr[i]\n",
    "        vs, ve = vad_arr[j]\n",
    "\n",
    "        inter = intersect(ds, de, vs, ve)\n",
    "        if inter is not None:\n",
    "            s, e = inter\n",
    "            dur = float(e - s)\n",
    "            if dur >= min_keep_sec:\n",
    "                rows.append({\n",
    "                    \"start_sec\": float(s),\n",
    "                    \"end_sec\": float(e),\n",
    "                    \"duration_sec\": dur,\n",
    "                    \"speaker_id\": spk\n",
    "                })\n",
    "\n",
    "        # advance the one that ends first\n",
    "        if de <= ve:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d975ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: compute speaker centroid embedding from segments\n",
    "import numpy as np\n",
    "\n",
    "def speaker_centroid_embedding_from_path(\n",
    "    wav_path,\n",
    "    segments,\n",
    "    emb_infer,\n",
    "    min_seg_sec: float = 1.0,\n",
    "    max_segments: int = 50,\n",
    "):\n",
    "    embs = []\n",
    "    total = 0.0\n",
    "    logged_error = False\n",
    "\n",
    "    # longest segments first (more stable embeddings)\n",
    "    segments = sorted(\n",
    "        segments, key=lambda s: float(s.end - s.start), reverse=True\n",
    "    )[:max_segments]\n",
    "\n",
    "    for seg in segments:\n",
    "        dur = float(seg.end - seg.start)\n",
    "        if dur < min_seg_sec:\n",
    "            continue\n",
    "        try:\n",
    "            v = emb_infer.crop(str(wav_path), seg)\n",
    "            v = np.array(v, dtype=np.float32).reshape(-1)\n",
    "            if np.linalg.norm(v) < 1e-6:\n",
    "                continue\n",
    "            embs.append(v)\n",
    "            total += dur\n",
    "        except Exception as e:\n",
    "            if not logged_error:\n",
    "                print(\"Embedding crop error (first one):\", repr(e))\n",
    "                logged_error = True\n",
    "            continue\n",
    "\n",
    "    if len(embs) == 0:\n",
    "        return None, 0.0\n",
    "\n",
    "    centroid = np.mean(np.stack(embs, axis=0), axis=0)\n",
    "    centroid = centroid / (np.linalg.norm(centroid) + 1e-12)\n",
    "    return centroid, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32637864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full duration (hours): 2.0364166666666668\n",
      "VAD intervals: 1745 first: [(2.43, 2.76), (7.71, 10.02), (11.1, 11.91)]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1) VAD ONCE (FULL AUDIO)\n",
    "# --------------------------\n",
    "info = sf.info(str(wav_path))\n",
    "full_duration = float(info.duration)\n",
    "\n",
    "vad_intervals = webrtc_vad_regions_streaming(\n",
    "    wav_path,\n",
    "    aggressiveness=VAD_AGGR,\n",
    "    frame_ms=VAD_FRAME_MS,\n",
    "    min_region_ms=VAD_MIN_REGION_MS\n",
    ")\n",
    "\n",
    "print(\"Full duration (hours):\", full_duration / 3600)\n",
    "print(\"VAD intervals:\", len(vad_intervals), \"first:\", vad_intervals[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d76ccf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VAD DataFrame\n",
    "vad_df = (\n",
    "    pd.DataFrame([{\n",
    "        \"participant_id\": participant_id,\n",
    "        \"session_date\": session_date,\n",
    "        \"recording_id\": recording_id,\n",
    "        \"wav_path\": str(wav_path),\n",
    "        \"start_sec\": s,\n",
    "        \"end_sec\": e,\n",
    "        \"duration_sec\": e - s,\n",
    "    } for s, e in vad_intervals])\n",
    "    .sort_values([\"start_sec\", \"end_sec\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52faa4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>session_date</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>wav_path</th>\n",
       "      <th>start_sec</th>\n",
       "      <th>end_sec</th>\n",
       "      <th>duration_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>7.71</td>\n",
       "      <td>10.02</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>11.10</td>\n",
       "      <td>11.91</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>13.32</td>\n",
       "      <td>14.61</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id session_date recording_id  \\\n",
       "0     ABAN141223     20250216   1739701628   \n",
       "1     ABAN141223     20250216   1739701628   \n",
       "2     ABAN141223     20250216   1739701628   \n",
       "3     ABAN141223     20250216   1739701628   \n",
       "4     ABAN141223     20250216   1739701628   \n",
       "\n",
       "                                            wav_path  start_sec  end_sec  \\\n",
       "0  /scratch/users/arunps/hindibabynet/audio_raw/A...       2.43     2.76   \n",
       "1  /scratch/users/arunps/hindibabynet/audio_raw/A...       7.71    10.02   \n",
       "2  /scratch/users/arunps/hindibabynet/audio_raw/A...      11.10    11.91   \n",
       "3  /scratch/users/arunps/hindibabynet/audio_raw/A...      13.32    14.61   \n",
       "4  /scratch/users/arunps/hindibabynet/audio_raw/A...      15.09    15.60   \n",
       "\n",
       "   duration_sec  \n",
       "0          0.33  \n",
       "1          2.31  \n",
       "2          0.81  \n",
       "3          1.29  \n",
       "4          0.51  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vad_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b33d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/arunps/Projects/HindiBabyNet/.venv/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turns collected: 1178\n",
      "Centroids collected: 24\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2) DIARIZATION PER CHUNK (with bounds) \n",
    "#    Store:\n",
    "#      - turns per chunk (local speaker id)\n",
    "#      - per-(chunk, local_speaker) centroid embedding\n",
    "# --------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "from pyannote.core import Segment\n",
    "\n",
    "def write_wav_chunk(wav_path: Path, chunk_path: Path, start_sec: float, end_sec: float):\n",
    "    info = sf.info(str(wav_path))\n",
    "    sr = info.samplerate\n",
    "\n",
    "    start_frame = int(start_sec * sr)\n",
    "    n_frames = int((end_sec - start_sec) * sr)\n",
    "\n",
    "    audio, _ = sf.read(str(wav_path), start=start_frame, frames=n_frames)\n",
    "    sf.write(str(chunk_path), audio, sr)\n",
    "    return chunk_path\n",
    "\n",
    "\n",
    "all_turn_rows = []\n",
    "centroid_rows = []\n",
    "\n",
    "# full wav used for embedding extraction\n",
    "file_full = {\"audio\": str(wav_path)}\n",
    "\n",
    "tmp_chunks_dir = Path(\"/scratch/users\") / Path.home().name / \"hindibabynet_tmp_chunks\"\n",
    "tmp_chunks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for chunk_id, chunk_start, chunk_end in make_chunks(full_duration, CHUNK_SEC, OVERLAP_SEC):\n",
    "\n",
    "    # write chunk wav\n",
    "    chunk_wav = tmp_chunks_dir / f\"{wav_path.stem}_chunk{chunk_id:04d}_{int(chunk_start)}_{int(chunk_end)}.wav\"\n",
    "    write_wav_chunk(wav_path, chunk_wav, chunk_start, chunk_end)\n",
    "\n",
    "    # diarize CHUNK wav \n",
    "    diar_chunk = pipeline(\n",
    "        {\"audio\": str(chunk_wav)},\n",
    "        min_speakers=MIN_SPEAKERS,\n",
    "        max_speakers=MAX_SPEAKERS\n",
    "    )\n",
    "\n",
    "    # collect turns \n",
    "    local_segments_by_spk = {}\n",
    "    for seg, _, spk in diar_chunk.itertracks(yield_label=True):\n",
    "        s = float(seg.start) + float(chunk_start)\n",
    "        e = float(seg.end) + float(chunk_start)\n",
    "        if e <= s:\n",
    "            continue\n",
    "\n",
    "        all_turn_rows.append({\n",
    "            \"participant_id\": participant_id,\n",
    "            \"session_date\": session_date,\n",
    "            \"recording_id\": recording_id,\n",
    "            \"wav_path\": str(wav_path),\n",
    "            \"chunk_id\": int(chunk_id),\n",
    "            \"chunk_start_sec\": float(chunk_start),\n",
    "            \"chunk_end_sec\": float(chunk_end),\n",
    "            \"speaker_id_local\": spk,\n",
    "            \"start_sec\": s,\n",
    "            \"end_sec\": e,\n",
    "            \"duration_sec\": float(e - s),\n",
    "            \"chunk_wav_path\": str(chunk_wav), # for debugging\n",
    "        })\n",
    "\n",
    "        # store ORIGINAL timeline segments for embedding extraction\n",
    "        local_segments_by_spk.setdefault(spk, []).append(Segment(s, e))\n",
    "\n",
    "    # compute centroid embeddings per local speaker (on FULL wav)\n",
    "    for spk, segs in local_segments_by_spk.items():\n",
    "        centroid, total_sec = speaker_centroid_embedding_from_path(\n",
    "            wav_path=wav_path,\n",
    "            segments=segs,\n",
    "            emb_infer=emb_infer,\n",
    "            min_seg_sec=MIN_EMB_SEG_SEC\n",
    "        )\n",
    "\n",
    "\n",
    "        if centroid is None:\n",
    "            continue\n",
    "\n",
    "        centroid_rows.append({\n",
    "            \"chunk_id\": int(chunk_id),\n",
    "            \"chunk_start_sec\": float(chunk_start),\n",
    "            \"chunk_end_sec\": float(chunk_end),\n",
    "            \"speaker_id_local\": spk,\n",
    "            \"total_sec_used\": float(total_sec),\n",
    "            \"centroid\": centroid,  # numpy vector\n",
    "        })\n",
    "\n",
    "print(\"Turns collected:\", len(all_turn_rows))\n",
    "print(\"Centroids collected:\", len(centroid_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1652563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>session_date</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>wav_path</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_start_sec</th>\n",
       "      <th>chunk_end_sec</th>\n",
       "      <th>speaker_id_local</th>\n",
       "      <th>start_sec</th>\n",
       "      <th>end_sec</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>chunk_wav_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>7.624719</td>\n",
       "      <td>9.885969</td>\n",
       "      <td>2.261250</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet_tmp_chunks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>13.294719</td>\n",
       "      <td>14.273469</td>\n",
       "      <td>0.978750</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet_tmp_chunks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>18.728469</td>\n",
       "      <td>20.095344</td>\n",
       "      <td>1.366875</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet_tmp_chunks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>20.770344</td>\n",
       "      <td>22.002219</td>\n",
       "      <td>1.231875</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet_tmp_chunks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>22.255344</td>\n",
       "      <td>23.807844</td>\n",
       "      <td>1.552500</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet_tmp_chunks/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id session_date recording_id  \\\n",
       "0     ABAN141223     20250216   1739701628   \n",
       "1     ABAN141223     20250216   1739701628   \n",
       "2     ABAN141223     20250216   1739701628   \n",
       "3     ABAN141223     20250216   1739701628   \n",
       "4     ABAN141223     20250216   1739701628   \n",
       "\n",
       "                                            wav_path  chunk_id  \\\n",
       "0  /scratch/users/arunps/hindibabynet/audio_raw/A...         0   \n",
       "1  /scratch/users/arunps/hindibabynet/audio_raw/A...         0   \n",
       "2  /scratch/users/arunps/hindibabynet/audio_raw/A...         0   \n",
       "3  /scratch/users/arunps/hindibabynet/audio_raw/A...         0   \n",
       "4  /scratch/users/arunps/hindibabynet/audio_raw/A...         0   \n",
       "\n",
       "   chunk_start_sec  chunk_end_sec speaker_id_local  start_sec    end_sec  \\\n",
       "0              0.0          900.0       SPEAKER_01   7.624719   9.885969   \n",
       "1              0.0          900.0       SPEAKER_01  13.294719  14.273469   \n",
       "2              0.0          900.0       SPEAKER_01  18.728469  20.095344   \n",
       "3              0.0          900.0       SPEAKER_01  20.770344  22.002219   \n",
       "4              0.0          900.0       SPEAKER_01  22.255344  23.807844   \n",
       "\n",
       "   duration_sec                                     chunk_wav_path  \n",
       "0      2.261250  /scratch/users/arunps/hindibabynet_tmp_chunks/...  \n",
       "1      0.978750  /scratch/users/arunps/hindibabynet_tmp_chunks/...  \n",
       "2      1.366875  /scratch/users/arunps/hindibabynet_tmp_chunks/...  \n",
       "3      1.231875  /scratch/users/arunps/hindibabynet_tmp_chunks/...  \n",
       "4      1.552500  /scratch/users/arunps/hindibabynet_tmp_chunks/...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turns_df = (\n",
    "    pd.DataFrame(all_turn_rows)\n",
    "      .sort_values([\"start_sec\", \"end_sec\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "turns_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4e1aef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids after min speech filter: 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_start_sec</th>\n",
       "      <th>chunk_end_sec</th>\n",
       "      <th>speaker_id_local</th>\n",
       "      <th>total_sec_used</th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>27.151875</td>\n",
       "      <td>[0.04787777, 0.030210864, -0.06240629, -0.0642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>10.243125</td>\n",
       "      <td>[-0.02877247, 0.02127275, -0.035593122, -0.048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3560.0</td>\n",
       "      <td>4460.0</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>25.751250</td>\n",
       "      <td>[0.03520787, -0.0027887593, 0.0023050124, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3560.0</td>\n",
       "      <td>4460.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>20.199375</td>\n",
       "      <td>[-0.00941363, -0.025264097, -0.08223153, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4450.0</td>\n",
       "      <td>5350.0</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "      <td>146.542500</td>\n",
       "      <td>[0.020359423, 0.0022690473, -0.040677346, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4450.0</td>\n",
       "      <td>5350.0</td>\n",
       "      <td>SPEAKER_02</td>\n",
       "      <td>11.626875</td>\n",
       "      <td>[-0.0037898656, 0.010166123, -0.05444234, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5340.0</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>182.182500</td>\n",
       "      <td>[0.036714647, -0.0077541065, -0.030207438, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>7130.0</td>\n",
       "      <td>SPEAKER_02</td>\n",
       "      <td>228.301875</td>\n",
       "      <td>[-0.0034936816, 0.08293282, 0.013763596, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>7130.0</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>29.463750</td>\n",
       "      <td>[-0.029796671, 0.08992742, -0.010794352, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>7130.0</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "      <td>22.798125</td>\n",
       "      <td>[0.0019078947, 0.070387736, 0.043161493, 0.048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>7130.0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>34.830000</td>\n",
       "      <td>[0.015969895, 0.026767138, -0.014984189, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>7120.0</td>\n",
       "      <td>7331.1</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>23.743125</td>\n",
       "      <td>[0.011922545, -0.012509087, 0.013617464, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>7120.0</td>\n",
       "      <td>7331.1</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>135.658125</td>\n",
       "      <td>[0.03253371, 0.030829003, 0.051321916, -0.0057...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunk_id  chunk_start_sec  chunk_end_sec speaker_id_local  total_sec_used  \\\n",
       "0          0              0.0          900.0       SPEAKER_01       27.151875   \n",
       "1          2           1780.0         2680.0       SPEAKER_01       10.243125   \n",
       "2          4           3560.0         4460.0       SPEAKER_00       25.751250   \n",
       "3          4           3560.0         4460.0       SPEAKER_01       20.199375   \n",
       "4          5           4450.0         5350.0       SPEAKER_03      146.542500   \n",
       "5          5           4450.0         5350.0       SPEAKER_02       11.626875   \n",
       "6          6           5340.0         6240.0       SPEAKER_01      182.182500   \n",
       "7          7           6230.0         7130.0       SPEAKER_02      228.301875   \n",
       "8          7           6230.0         7130.0       SPEAKER_00       29.463750   \n",
       "9          7           6230.0         7130.0       SPEAKER_03       22.798125   \n",
       "10         7           6230.0         7130.0       SPEAKER_01       34.830000   \n",
       "11         8           7120.0         7331.1       SPEAKER_00       23.743125   \n",
       "12         8           7120.0         7331.1       SPEAKER_01      135.658125   \n",
       "\n",
       "                                             centroid  \n",
       "0   [0.04787777, 0.030210864, -0.06240629, -0.0642...  \n",
       "1   [-0.02877247, 0.02127275, -0.035593122, -0.048...  \n",
       "2   [0.03520787, -0.0027887593, 0.0023050124, -0.0...  \n",
       "3   [-0.00941363, -0.025264097, -0.08223153, -0.02...  \n",
       "4   [0.020359423, 0.0022690473, -0.040677346, -0.0...  \n",
       "5   [-0.0037898656, 0.010166123, -0.05444234, -0.0...  \n",
       "6   [0.036714647, -0.0077541065, -0.030207438, -0....  \n",
       "7   [-0.0034936816, 0.08293282, 0.013763596, -0.01...  \n",
       "8   [-0.029796671, 0.08992742, -0.010794352, -0.04...  \n",
       "9   [0.0019078947, 0.070387736, 0.043161493, 0.048...  \n",
       "10  [0.015969895, 0.026767138, -0.014984189, -0.03...  \n",
       "11  [0.011922545, -0.012509087, 0.013617464, 0.015...  \n",
       "12  [0.03253371, 0.030829003, 0.051321916, -0.0057...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids_df = pd.DataFrame(centroid_rows)\n",
    "# keep only stable centroids (enough speech)\n",
    "centroids_df = centroids_df[centroids_df[\"total_sec_used\"] >= MIN_SPK_TOTAL_SEC_FOR_CENTROID].reset_index(drop=True)\n",
    "\n",
    "print(\"Centroids after min speech filter:\", len(centroids_df))\n",
    "centroids_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d785228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global speakers found: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>speaker_id_local</th>\n",
       "      <th>total_sec_used</th>\n",
       "      <th>speaker_id_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>27.151875</td>\n",
       "      <td>GSPK_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>10.243125</td>\n",
       "      <td>GSPK_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>25.751250</td>\n",
       "      <td>GSPK_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>20.199375</td>\n",
       "      <td>GSPK_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "      <td>146.542500</td>\n",
       "      <td>GSPK_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>SPEAKER_02</td>\n",
       "      <td>11.626875</td>\n",
       "      <td>GSPK_04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>182.182500</td>\n",
       "      <td>GSPK_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>SPEAKER_02</td>\n",
       "      <td>228.301875</td>\n",
       "      <td>GSPK_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>29.463750</td>\n",
       "      <td>GSPK_06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "      <td>22.798125</td>\n",
       "      <td>GSPK_07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id speaker_id_local  total_sec_used speaker_id_global\n",
       "0         0       SPEAKER_01       27.151875           GSPK_00\n",
       "1         2       SPEAKER_01       10.243125           GSPK_01\n",
       "2         4       SPEAKER_00       25.751250           GSPK_02\n",
       "3         4       SPEAKER_01       20.199375           GSPK_03\n",
       "4         5       SPEAKER_03      146.542500           GSPK_03\n",
       "5         5       SPEAKER_02       11.626875           GSPK_04\n",
       "6         6       SPEAKER_01      182.182500           GSPK_03\n",
       "7         7       SPEAKER_02      228.301875           GSPK_05\n",
       "8         7       SPEAKER_00       29.463750           GSPK_06\n",
       "9         7       SPEAKER_03       22.798125           GSPK_07"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# GLOBAL SPEAKER MERGING (across chunks)\n",
    "#    Cosine-threshold graph clustering on centroids\n",
    "# --------------------------\n",
    "def cosine_sim_matrix(X):\n",
    "    # X should already be L2-normalized\n",
    "    return X @ X.T\n",
    "\n",
    "# build matrix\n",
    "X = np.stack(centroids_df[\"centroid\"].to_numpy(), axis=0).astype(np.float32)\n",
    "S = cosine_sim_matrix(X)\n",
    "\n",
    "# graph edges where sim >= threshold\n",
    "thr = COS_SIM_MERGE_THRESHOLD\n",
    "n = S.shape[0]\n",
    "visited = np.zeros(n, dtype=bool)\n",
    "global_labels = -np.ones(n, dtype=int)\n",
    "\n",
    "gid = 0\n",
    "for i in range(n):\n",
    "    if visited[i]:\n",
    "        continue\n",
    "    # BFS/DFS\n",
    "    stack = [i]\n",
    "    visited[i] = True\n",
    "    global_labels[i] = gid\n",
    "    while stack:\n",
    "        u = stack.pop()\n",
    "        # neighbors above threshold\n",
    "        nbrs = np.where((S[u] >= thr) & (~visited))[0]\n",
    "        for v in nbrs:\n",
    "            visited[v] = True\n",
    "            global_labels[v] = gid\n",
    "            stack.append(v)\n",
    "    gid += 1\n",
    "\n",
    "centroids_df[\"speaker_id_global\"] = [f\"GSPK_{k:02d}\" for k in global_labels]\n",
    "print(\"Global speakers found:\", centroids_df[\"speaker_id_global\"].nunique())\n",
    "centroids_df[[\"chunk_id\",\"speaker_id_local\",\"total_sec_used\",\"speaker_id_global\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c47b0a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mapped (chunk, local): 24\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Create mapping: (chunk_id, speaker_id_local) -> speaker_id_global\n",
    "#    For local speakers that didn't get a stable centroid (too little speech),\n",
    "#    assign them to the nearest global centroid available (fallback).\n",
    "# --------------------------\n",
    "# Build lookup for stable mappings\n",
    "map_df = centroids_df[[\"chunk_id\", \"speaker_id_local\", \"speaker_id_global\"]].drop_duplicates()\n",
    "\n",
    "# precompute global centroids (one vector per global speaker)\n",
    "global_centroids = {}\n",
    "for gspk, g in centroids_df.groupby(\"speaker_id_global\"):\n",
    "    G = np.stack(g[\"centroid\"].to_numpy(), axis=0)\n",
    "    c = np.mean(G, axis=0)\n",
    "    c = c / (np.linalg.norm(c) + 1e-12)\n",
    "    global_centroids[gspk] = c\n",
    "\n",
    "gspk_list = sorted(global_centroids.keys())\n",
    "Gmat = np.stack([global_centroids[g] for g in gspk_list], axis=0)  # (G, dim)\n",
    "\n",
    "# Find chunk-local speakers missing in mapping\n",
    "all_pairs = turns_df[[\"chunk_id\", \"speaker_id_local\"]].drop_duplicates()\n",
    "mapped_pairs = map_df[[\"chunk_id\", \"speaker_id_local\"]].drop_duplicates()\n",
    "missing_pairs = all_pairs.merge(mapped_pairs, on=[\"chunk_id\",\"speaker_id_local\"], how=\"left\", indicator=True)\n",
    "missing_pairs = missing_pairs[missing_pairs[\"_merge\"] == \"left_only\"][[\"chunk_id\",\"speaker_id_local\"]]\n",
    "\n",
    "# For each missing pair, build a centroid with relaxed constraints and assign nearest global\n",
    "extra_rows = []\n",
    "for r in missing_pairs.itertuples(index=False):\n",
    "    cid = int(r.chunk_id)\n",
    "    spk = r.speaker_id_local\n",
    "\n",
    "    segs = turns_df[(turns_df[\"chunk_id\"] == cid) & (turns_df[\"speaker_id_local\"] == spk)]\n",
    "    seg_objs = [Segment(float(a), float(b)) for a, b in segs[[\"start_sec\",\"end_sec\"]].to_numpy()]\n",
    "\n",
    "    centroid, total_sec = speaker_centroid_embedding_from_path(\n",
    "            wav_path=wav_path,\n",
    "            segments=seg_objs,\n",
    "            emb_infer=emb_infer,\n",
    "            min_seg_sec=MIN_EMB_SEG_SEC\n",
    "        )\n",
    "\n",
    "    if centroid is None or len(gspk_list) == 0:\n",
    "        continue\n",
    "\n",
    "    # nearest by cosine (vectors normalized)\n",
    "    sims = Gmat @ centroid\n",
    "    best_idx = int(np.argmax(sims))\n",
    "    best_g = gspk_list[best_idx]\n",
    "\n",
    "    extra_rows.append({\"chunk_id\": cid, \"speaker_id_local\": spk, \"speaker_id_global\": best_g})\n",
    "\n",
    "if extra_rows:\n",
    "    map_df = pd.concat([map_df, pd.DataFrame(extra_rows)], ignore_index=True)\n",
    "\n",
    "# final mapping dict\n",
    "map_dict = {(int(r.chunk_id), r.speaker_id_local): r.speaker_id_global for r in map_df.itertuples(index=False)}\n",
    "\n",
    "print(\"Total mapped (chunk, local):\", len(map_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54871986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>session_date</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>wav_path</th>\n",
       "      <th>start_sec</th>\n",
       "      <th>end_sec</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>speaker_id_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>7.624719</td>\n",
       "      <td>9.885969</td>\n",
       "      <td>2.261250</td>\n",
       "      <td>GSPK_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>13.294719</td>\n",
       "      <td>14.273469</td>\n",
       "      <td>0.978750</td>\n",
       "      <td>GSPK_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>18.728469</td>\n",
       "      <td>20.095344</td>\n",
       "      <td>1.366875</td>\n",
       "      <td>GSPK_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>20.770344</td>\n",
       "      <td>22.002219</td>\n",
       "      <td>1.231875</td>\n",
       "      <td>GSPK_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>22.255344</td>\n",
       "      <td>23.807844</td>\n",
       "      <td>1.552500</td>\n",
       "      <td>GSPK_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>24.533469</td>\n",
       "      <td>25.090344</td>\n",
       "      <td>0.556875</td>\n",
       "      <td>GSPK_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>27.975969</td>\n",
       "      <td>30.675969</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>GSPK_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>33.021594</td>\n",
       "      <td>35.839719</td>\n",
       "      <td>2.818125</td>\n",
       "      <td>GSPK_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>34.624719</td>\n",
       "      <td>34.759719</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>GSPK_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABAN141223</td>\n",
       "      <td>20250216</td>\n",
       "      <td>1739701628</td>\n",
       "      <td>/scratch/users/arunps/hindibabynet/audio_raw/A...</td>\n",
       "      <td>35.215344</td>\n",
       "      <td>35.822844</td>\n",
       "      <td>0.607500</td>\n",
       "      <td>GSPK_03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id session_date recording_id  \\\n",
       "0     ABAN141223     20250216   1739701628   \n",
       "1     ABAN141223     20250216   1739701628   \n",
       "2     ABAN141223     20250216   1739701628   \n",
       "3     ABAN141223     20250216   1739701628   \n",
       "4     ABAN141223     20250216   1739701628   \n",
       "5     ABAN141223     20250216   1739701628   \n",
       "6     ABAN141223     20250216   1739701628   \n",
       "7     ABAN141223     20250216   1739701628   \n",
       "8     ABAN141223     20250216   1739701628   \n",
       "9     ABAN141223     20250216   1739701628   \n",
       "\n",
       "                                            wav_path  start_sec    end_sec  \\\n",
       "0  /scratch/users/arunps/hindibabynet/audio_raw/A...   7.624719   9.885969   \n",
       "1  /scratch/users/arunps/hindibabynet/audio_raw/A...  13.294719  14.273469   \n",
       "2  /scratch/users/arunps/hindibabynet/audio_raw/A...  18.728469  20.095344   \n",
       "3  /scratch/users/arunps/hindibabynet/audio_raw/A...  20.770344  22.002219   \n",
       "4  /scratch/users/arunps/hindibabynet/audio_raw/A...  22.255344  23.807844   \n",
       "5  /scratch/users/arunps/hindibabynet/audio_raw/A...  24.533469  25.090344   \n",
       "6  /scratch/users/arunps/hindibabynet/audio_raw/A...  27.975969  30.675969   \n",
       "7  /scratch/users/arunps/hindibabynet/audio_raw/A...  33.021594  35.839719   \n",
       "8  /scratch/users/arunps/hindibabynet/audio_raw/A...  34.624719  34.759719   \n",
       "9  /scratch/users/arunps/hindibabynet/audio_raw/A...  35.215344  35.822844   \n",
       "\n",
       "   duration_sec speaker_id_global  \n",
       "0      2.261250           GSPK_00  \n",
       "1      0.978750           GSPK_00  \n",
       "2      1.366875           GSPK_00  \n",
       "3      1.231875           GSPK_00  \n",
       "4      1.552500           GSPK_00  \n",
       "5      0.556875           GSPK_00  \n",
       "6      2.700000           GSPK_00  \n",
       "7      2.818125           GSPK_00  \n",
       "8      0.135000           GSPK_03  \n",
       "9      0.607500           GSPK_03  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Relabel turns_df with global speakers\n",
    "# --------------------------\n",
    "def map_global(row):\n",
    "    return map_dict.get((int(row[\"chunk_id\"]), row[\"speaker_id_local\"]), None)\n",
    "\n",
    "turns_df[\"speaker_id_global\"] = turns_df.apply(map_global, axis=1)\n",
    "\n",
    "# drop any segments we couldn't map (rare)\n",
    "turns_df = turns_df.dropna(subset=[\"speaker_id_global\"]).reset_index(drop=True)\n",
    "\n",
    "# Keep only columns needed downstream + global speaker id\n",
    "diar_global_df = turns_df[[\n",
    "    \"participant_id\",\"session_date\",\"recording_id\",\"wav_path\",\n",
    "    \"start_sec\",\"end_sec\",\"duration_sec\",\n",
    "    \"speaker_id_global\"\n",
    "]].sort_values([\"start_sec\",\"end_sec\"]).reset_index(drop=True)\n",
    "\n",
    "diar_global_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61ffb20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  participant_id session_date recording_id  \\\n",
       " 0     ABAN141223     20250216   1739701628   \n",
       " 1     ABAN141223     20250216   1739701628   \n",
       " 2     ABAN141223     20250216   1739701628   \n",
       " 3     ABAN141223     20250216   1739701628   \n",
       " 4     ABAN141223     20250216   1739701628   \n",
       " \n",
       "                                             wav_path  start_sec    end_sec  \\\n",
       " 0  /scratch/users/arunps/hindibabynet/audio_raw/A...   7.710000   9.885969   \n",
       " 1  /scratch/users/arunps/hindibabynet/audio_raw/A...  13.320000  14.273469   \n",
       " 2  /scratch/users/arunps/hindibabynet/audio_raw/A...  18.728469  20.095344   \n",
       " 3  /scratch/users/arunps/hindibabynet/audio_raw/A...  20.790000  22.002219   \n",
       " 4  /scratch/users/arunps/hindibabynet/audio_raw/A...  22.320000  23.807844   \n",
       " \n",
       "    duration_sec speaker_id  \n",
       " 0      2.175969    GSPK_00  \n",
       " 1      0.953469    GSPK_00  \n",
       " 2      1.366875    GSPK_00  \n",
       " 3      1.212219    GSPK_00  \n",
       " 4      1.487844    GSPK_00  ,\n",
       " 983)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# INTERSECT diarization (global speakers) with VAD speech intervals\n",
    "# --------------------------\n",
    "speech_only_df = intersect_diar_with_vad(\n",
    "    diar_df=diar_global_df,\n",
    "    vad_intervals=vad_intervals,\n",
    "    min_keep_sec=MIN_KEEP_SEC\n",
    ")\n",
    "\n",
    "# attach required metadata columns (exact ones you asked for) + speaker_id\n",
    "speech_only_df.insert(0, \"wav_path\", str(wav_path))\n",
    "speech_only_df.insert(0, \"recording_id\", recording_id)\n",
    "speech_only_df.insert(0, \"session_date\", session_date)\n",
    "speech_only_df.insert(0, \"participant_id\", participant_id)\n",
    "\n",
    "# reorder columns\n",
    "final_df_full = speech_only_df[[\n",
    "    \"participant_id\",\"session_date\",\"recording_id\",\"wav_path\",\n",
    "    \"start_sec\",\"end_sec\",\"duration_sec\",\n",
    "    \"speaker_id\"\n",
    "]].sort_values([\"start_sec\",\"end_sec\"]).reset_index(drop=True)\n",
    "\n",
    "final_df_full.head(), len(final_df_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "264e2fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker_id\n",
       "GSPK_03    659.785594\n",
       "GSPK_05    546.152406\n",
       "GSPK_06     34.040625\n",
       "GSPK_08     32.440063\n",
       "GSPK_09     31.674375\n",
       "GSPK_02     30.663094\n",
       "GSPK_01     28.447500\n",
       "GSPK_00     28.093437\n",
       "GSPK_07     27.453094\n",
       "GSPK_04     17.114437\n",
       "Name: duration_sec, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Quick sanity checks\n",
    "# --------------------------\n",
    "final_df_full.groupby(\"speaker_id\")[\"duration_sec\"].sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a32587d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from praatio import textgrid as tgio\n",
    "\n",
    "\n",
    "def _make_interval_tier(name, entries, xmin, xmax):\n",
    "    \"\"\"\n",
    "    Create IntervalTier across praatio versions.\n",
    "    \"\"\"\n",
    "    # IntervalTier(name, entries, minT, maxT)\n",
    "    try:\n",
    "        return tgio.IntervalTier(str(name), entries, xmin, xmax)\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    # IntervalTier(name, entries=..., minT=..., maxT=...)\n",
    "    try:\n",
    "        return tgio.IntervalTier(name=str(name), entries=entries, minT=xmin, maxT=xmax)\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    # IntervalTier(name, entryList=..., minT=..., maxT=...)\n",
    "    return tgio.IntervalTier(name=str(name), entryList=entries, minT=xmin, maxT=xmax)\n",
    "\n",
    "\n",
    "def df_to_textgrid_by_speaker(\n",
    "    df: pd.DataFrame,\n",
    "    wav_path: Path,\n",
    "    out_textgrid_path: Path,\n",
    "    start_col: str = \"start_sec\",\n",
    "    end_col: str = \"end_sec\",\n",
    "    speaker_col: str = \"speaker_id\",\n",
    "    label_col: str | None = None,  # None -> label = speaker_id\n",
    "):\n",
    "    wav_path = Path(wav_path)\n",
    "    out_textgrid_path = Path(out_textgrid_path)\n",
    "\n",
    "    info = sf.info(str(wav_path))\n",
    "    xmin = 0.0\n",
    "    xmax = float(info.duration)\n",
    "\n",
    "    df = df.copy()\n",
    "    df = df[df[end_col] > df[start_col]].sort_values([speaker_col, start_col, end_col])\n",
    "\n",
    "    tg = tgio.Textgrid()\n",
    "    tg.minTimestamp = xmin\n",
    "    tg.maxTimestamp = xmax\n",
    "\n",
    "    for spk, g in df.groupby(speaker_col):\n",
    "        entries = []\n",
    "        for r in g.itertuples(index=False):\n",
    "            s = float(getattr(r, start_col))\n",
    "            e = float(getattr(r, end_col))\n",
    "\n",
    "            # clamp\n",
    "            s = max(xmin, min(s, xmax))\n",
    "            e = max(xmin, min(e, xmax))\n",
    "            if e <= s:\n",
    "                continue\n",
    "\n",
    "            lab = str(spk) if label_col is None else str(getattr(r, label_col))\n",
    "            entries.append((s, e, lab))\n",
    "\n",
    "        # ensure non-overlap within the speaker tier\n",
    "        entries.sort(key=lambda x: (x[0], x[1]))\n",
    "        cleaned = []\n",
    "        last_end = -1.0\n",
    "        for s, e, lab in entries:\n",
    "            if s < last_end:\n",
    "                s = last_end\n",
    "            if e > s:\n",
    "                cleaned.append((s, e, lab))\n",
    "                last_end = e\n",
    "\n",
    "        tier = _make_interval_tier(str(spk), cleaned, xmin, xmax)\n",
    "        tg.addTier(tier)\n",
    "\n",
    "    tg.save(str(out_textgrid_path), format=\"short_textgrid\", includeBlankSpaces=True)\n",
    "    return out_textgrid_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8da518ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/scratch/users/arunps/hindibabynet_tmp/1739701628.TextGrid')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tmp_dir = Path(\"/scratch/users\") / Path.home().name / \"hindibabynet_tmp\"\n",
    "tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tg_path = df_to_textgrid_by_speaker(\n",
    "    df=final_df_full,                         # diarization  VAD DataFrame\n",
    "    wav_path=wav_path,                   # full audio file\n",
    "    out_textgrid_path=tmp_dir / f\"{wav_path.stem}.TextGrid\",\n",
    ")\n",
    "\n",
    "tg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "efcebb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted temporary chunk directory: /scratch/users/arunps/hindibabynet_tmp_chunks\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# CLEANUP: remove all chunk WAVs at once\n",
    "# --------------------------\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "tmp_chunks_dir = Path(\"/scratch/users\") / Path.home().name / \"hindibabynet_tmp_chunks\"\n",
    "\n",
    "if tmp_chunks_dir.exists():\n",
    "    shutil.rmtree(tmp_chunks_dir)\n",
    "    print(f\"Deleted temporary chunk directory: {tmp_chunks_dir}\")\n",
    "else:\n",
    "    print(\"No temporary chunk directory found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HindiBabyNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
