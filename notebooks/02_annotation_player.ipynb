{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27e21cb",
   "metadata": {},
   "source": [
    "# ADS / IDS Annotation Tool\n",
    "\n",
    "**Everything happens here** â€” listen to segments and label them without leaving this notebook.\n",
    "\n",
    "### Workflow\n",
    "1. **Cell 2** â€” Configure participant, speaker & parquet path\n",
    "2. **Cell 3** â€” Load audio & segment boundaries from Stage 03 parquet\n",
    "3. **Cell 4** â€” Annotate: plays each segment, you type `0` / `1` / `2` and press Enter\n",
    "4. **Cell 5** â€” Export labeled ADS & IDS WAV files\n",
    "\n",
    "### Labels\n",
    "| Input | Label |\n",
    "|-------|-------|\n",
    "| `0` | Other |\n",
    "| `1` | ADS (Adult-Directed Speech) |\n",
    "| `2` | IDS (Infant-Directed Speech) |\n",
    "| `r` | Replay current segment |\n",
    "| `b` | Go back one segment |\n",
    "| `q` | Save & stop (resume later) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PARTICIPANT_ID = \"ABAN141223\"       # â† change this\n",
    "SPEAKER        = \"female\"           # \"female\" or \"male\"\n",
    "\n",
    "# Paths (no need to change unless non-default)\n",
    "CLASSIFIED_ROOT  = \"/scratch/users/arunps/hindibabynet/audio_classified\"\n",
    "ANNOTATION_ROOT  = \"/scratch/users/arunps/hindibabynet/annotations\"\n",
    "ARTIFACTS_ROOT   = \"../artifacts/runs\"   # relative to notebook\n",
    "\n",
    "# Parquet path â€“ set to \"\" to auto-discover the latest run\n",
    "PARQUET_PATH = \"\"  # e.g. \"../artifacts/runs/20260212_134452/speaker_classification/ABAN141223_segments.parquet\"\n",
    "\n",
    "# Gap inserted between segments when pipeline built main_female/male.wav\n",
    "STREAM_GAP_SEC = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, wave, time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "LABEL_MAP = {0: \"Other\", 1: \"ADS\", 2: \"IDS\"}\n",
    "SPEAKER_CLASS_MAP = {\"female\": \"adult_female\", \"male\": \"adult_male\"}\n",
    "\n",
    "# â”€â”€ Read WAV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def read_wav(path):\n",
    "    with wave.open(str(path), \"rb\") as wf:\n",
    "        sr = wf.getframerate()\n",
    "        raw = wf.readframes(wf.getnframes())\n",
    "    return np.frombuffer(raw, dtype=np.int16).astype(np.float32) / 32768.0, sr\n",
    "\n",
    "# â”€â”€ Parquet-based segment loading â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def find_segments_parquet(artifacts_root: str, participant_id: str) -> Optional[Path]:\n",
    "    \"\"\"Auto-discover the latest Stage 03 segments parquet for a participant.\"\"\"\n",
    "    root = Path(artifacts_root)\n",
    "    pattern = f\"*/speaker_classification/{participant_id}_segments.parquet\"\n",
    "    candidates = sorted(root.glob(pattern))\n",
    "    return candidates[-1] if candidates else None\n",
    "\n",
    "def load_segments_from_parquet(\n",
    "    parquet_path: Path,\n",
    "    speaker: str,\n",
    "    gap_sec: float = 0.15,\n",
    ") -> Tuple[List[Tuple[float, float]], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load classified segments from the Stage 03 parquet and reconstruct\n",
    "    their positions inside main_female.wav / main_male.wav.\n",
    "\n",
    "    The pipeline's build_class_stream concatenates segments (sorted by\n",
    "    start_sec) with gap_sec silence gaps. We replicate that to compute\n",
    "    each segment's (stream_start, stream_end) inside the WAV.\n",
    "    \"\"\"\n",
    "    target_class = SPEAKER_CLASS_MAP[speaker]\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "\n",
    "    seg_df = (\n",
    "        df[df[\"predicted_class\"] == target_class]\n",
    "        .copy()\n",
    "        .sort_values(\"start_sec\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if seg_df.empty:\n",
    "        return [], seg_df\n",
    "\n",
    "    segments: List[Tuple[float, float]] = []\n",
    "    cursor = 0.0\n",
    "    for _, row in seg_df.iterrows():\n",
    "        dur = float(row[\"duration_sec\"])\n",
    "        segments.append((cursor, cursor + dur))\n",
    "        cursor += dur + gap_sec\n",
    "\n",
    "    return segments, seg_df\n",
    "\n",
    "# â”€â”€ CSV persistence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def csv_path(pid, speaker):\n",
    "    return Path(ANNOTATION_ROOT) / pid / f\"{pid}_{speaker}_annotations.csv\"\n",
    "\n",
    "def load_ann(pid, speaker, segments):\n",
    "    p = csv_path(pid, speaker)\n",
    "    if not p.exists(): return {}\n",
    "    ann = {}\n",
    "    with open(p, newline=\"\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            ann[int(row[\"segment_index\"])] = int(row[\"label\"])\n",
    "    return ann\n",
    "\n",
    "def save_ann(pid, speaker, segments, annotations, seg_df=None):\n",
    "    p = csv_path(pid, speaker)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    has_meta = seg_df is not None and not seg_df.empty\n",
    "    with open(p, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        header = [\"segment_index\", \"start_sec\", \"end_sec\", \"duration_sec\", \"label\", \"label_name\"]\n",
    "        if has_meta:\n",
    "            header += [\"orig_start_sec\", \"orig_end_sec\", \"chunk_id\", \"predicted_confidence\"]\n",
    "        w.writerow(header)\n",
    "        for idx in sorted(annotations.keys()):\n",
    "            if idx < len(segments):\n",
    "                s, e = segments[idx]\n",
    "                lab = annotations[idx]\n",
    "                row = [idx, f\"{s:.4f}\", f\"{e:.4f}\", f\"{e-s:.4f}\", lab, LABEL_MAP[lab]]\n",
    "                if has_meta and idx < len(seg_df):\n",
    "                    r = seg_df.iloc[idx]\n",
    "                    row += [\n",
    "                        f\"{r['start_sec']:.4f}\",\n",
    "                        f\"{r['end_sec']:.4f}\",\n",
    "                        int(r[\"chunk_id\"]) if \"chunk_id\" in r.index else \"\",\n",
    "                        f\"{r['predicted_confidence']:.4f}\" if \"predicted_confidence\" in r.index else \"\",\n",
    "                    ]\n",
    "                w.writerow(row)\n",
    "    return p\n",
    "\n",
    "# â”€â”€ Load audio & segments from parquet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "wav_path = Path(CLASSIFIED_ROOT) / PARTICIPANT_ID / f\"{PARTICIPANT_ID}_main_{SPEAKER}.wav\"\n",
    "assert wav_path.exists(), f\"File not found: {wav_path}\"\n",
    "\n",
    "print(f\"Loading {wav_path.name} ...\")\n",
    "audio, sr = read_wav(wav_path)\n",
    "dur = len(audio) / sr\n",
    "print(f\"Duration: {dur:.1f}s ({dur/60:.1f} min)  |  SR: {sr} Hz\")\n",
    "\n",
    "# Resolve parquet\n",
    "if PARQUET_PATH:\n",
    "    pq_path = Path(PARQUET_PATH)\n",
    "else:\n",
    "    pq_path = find_segments_parquet(ARTIFACTS_ROOT, PARTICIPANT_ID)\n",
    "assert pq_path is not None and pq_path.exists(), (\n",
    "    f\"Segments parquet not found for {PARTICIPANT_ID}.\\n\"\n",
    "    f\"  Searched: {ARTIFACTS_ROOT}/*/speaker_classification/{PARTICIPANT_ID}_segments.parquet\\n\"\n",
    "    f\"  Set PARQUET_PATH in the config cell to specify explicitly.\"\n",
    ")\n",
    "print(f\"Using parquet: {pq_path}\")\n",
    "\n",
    "print(f\"Loading segments from parquet (class={SPEAKER_CLASS_MAP[SPEAKER]}) ...\")\n",
    "segments, seg_df = load_segments_from_parquet(pq_path, SPEAKER, gap_sec=STREAM_GAP_SEC)\n",
    "durs = [e - s for s, e in segments]\n",
    "print(f\"Found {len(segments)} segments  |  \"\n",
    "      f\"min={min(durs):.2f}s  median={sorted(durs)[len(durs)//2]:.2f}s  max={max(durs):.2f}s\")\n",
    "\n",
    "# Load existing annotations\n",
    "annotations = load_ann(PARTICIPANT_ID, SPEAKER, segments)\n",
    "if annotations:\n",
    "    print(f\"Loaded {len(annotations)} existing annotations (will resume from where you left off)\")\n",
    "print(f\"\\nâœ“ Ready â€” run the next cell to start annotating.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Annotate: listen + label in one loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Re-run this cell to resume from where you left off.\n",
    "\n",
    "total = len(segments)\n",
    "# Find first unannotated segment\n",
    "start_idx = 0\n",
    "unannotated = [i for i in range(total) if i not in annotations]\n",
    "if unannotated:\n",
    "    start_idx = unannotated[0]\n",
    "else:\n",
    "    print(f\"All {total} segments already annotated! Run the export cell below.\")\n",
    "\n",
    "n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "print(f\"Progress: {len(annotations)}/{total} annotated  |  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "print(f\"Starting from segment {start_idx + 1}\\n\")\n",
    "print(\"Labels:  0=Other  1=ADS  2=IDS  |  r=replay  b=back  q=save & stop\\n\")\n",
    "\n",
    "idx = start_idx\n",
    "try:\n",
    "    while 0 <= idx < total:\n",
    "        s, e = segments[idx]\n",
    "        dur_s = e - s\n",
    "        existing = annotations.get(idx)\n",
    "        tag = f\"  [current: {LABEL_MAP[existing]}]\" if existing is not None else \"\"\n",
    "\n",
    "        # Show original-recording times from parquet if available\n",
    "        orig_info = \"\"\n",
    "        if not seg_df.empty and idx < len(seg_df):\n",
    "            r = seg_df.iloc[idx]\n",
    "            orig_info = f\"  (orig: {r['start_sec']:.2f}sâ€“{r['end_sec']:.2f}s)\"\n",
    "\n",
    "        # Extract segment audio\n",
    "        s_samp = max(0, int(s * sr))\n",
    "        e_samp = min(len(audio), int(e * sr))\n",
    "        chunk = audio[s_samp:e_samp]\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "        n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "        n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "        print(f\"[{idx+1}/{total}]  {s:.2f}s â€“ {e:.2f}s  ({dur_s:.2f}s){tag}{orig_info}\")\n",
    "        print(f\"Progress: {len(annotations)}/{total}  |  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "        print(\"â”€\" * 50)\n",
    "\n",
    "        # Play audio (autoplay in browser)\n",
    "        display(ipd.Audio(chunk, rate=sr, autoplay=True))\n",
    "\n",
    "        while True:\n",
    "            raw = input(\"Label (0/1/2/r/b/q): \").strip().lower()\n",
    "            if raw == \"q\":\n",
    "                save_ann(PARTICIPANT_ID, SPEAKER, segments, annotations, seg_df)\n",
    "                clear_output(wait=True)\n",
    "                n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "                n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "                n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "                print(f\"âœ“ Saved {len(annotations)}/{total} annotations.  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "                print(f\"  CSV: {csv_path(PARTICIPANT_ID, SPEAKER)}\")\n",
    "                print(f\"  Re-run this cell to resume.\")\n",
    "                raise StopIteration\n",
    "            elif raw == \"r\":\n",
    "                clear_output(wait=True)\n",
    "                print(f\"[{idx+1}/{total}]  {s:.2f}s â€“ {e:.2f}s  ({dur_s:.2f}s)  (replaying...)\")\n",
    "                print(f\"Progress: {len(annotations)}/{total}  |  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "                print(\"â”€\" * 50)\n",
    "                display(ipd.Audio(chunk, rate=sr, autoplay=True))\n",
    "                continue\n",
    "            elif raw == \"b\":\n",
    "                if idx > 0:\n",
    "                    idx -= 1\n",
    "                break\n",
    "            elif raw in (\"0\", \"1\", \"2\"):\n",
    "                annotations[idx] = int(raw)\n",
    "                idx += 1\n",
    "                # Auto-save every 10\n",
    "                if len(annotations) % 10 == 0:\n",
    "                    save_ann(PARTICIPANT_ID, SPEAKER, segments, annotations, seg_df)\n",
    "                break\n",
    "            else:\n",
    "                print(\"  Invalid. Use 0, 1, 2, r, b, or q.\")\n",
    "\n",
    "    # Finished all segments\n",
    "    save_ann(PARTICIPANT_ID, SPEAKER, segments, annotations, seg_df)\n",
    "    clear_output(wait=True)\n",
    "    n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "    n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "    n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "    print(f\"ðŸŽ‰ All {total} segments annotated!  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "    print(f\"CSV: {csv_path(PARTICIPANT_ID, SPEAKER)}\")\n",
    "    print(f\"Run the export cell below to create separate WAV files.\")\n",
    "\n",
    "except StopIteration:\n",
    "    pass\n",
    "except KeyboardInterrupt:\n",
    "    save_ann(PARTICIPANT_ID, SPEAKER, segments, annotations, seg_df)\n",
    "    print(f\"\\nInterrupted â€” saved {len(annotations)} annotations. Re-run to resume.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Export: create separate ADS / IDS / Other WAV files â”€â”€â”€â”€â”€â”€\n",
    "# Run this after annotation is complete (or partially complete).\n",
    "\n",
    "def write_wav16(path, data, sr):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pcm = np.clip(data * 32768.0, -32768, 32767).astype(np.int16)\n",
    "    with wave.open(str(path), \"wb\") as wf:\n",
    "        wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(sr)\n",
    "        wf.writeframes(pcm.tobytes())\n",
    "\n",
    "out_dir = Path(ANNOTATION_ROOT) / PARTICIPANT_ID\n",
    "gap = np.zeros(int(sr * 0.15), dtype=np.float32)\n",
    "\n",
    "n_ann = len(annotations)\n",
    "n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "print(f\"Annotations: {n_ann}/{len(segments)}  |  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\\n\")\n",
    "\n",
    "for label_code, label_name in LABEL_MAP.items():\n",
    "    pieces = []\n",
    "    for idx, lab in sorted(annotations.items()):\n",
    "        if lab != label_code or idx >= len(segments): continue\n",
    "        s, e = segments[idx]\n",
    "        chunk = audio[max(0, int(s*sr)):min(len(audio), int(e*sr))]\n",
    "        if len(chunk) > 0:\n",
    "            pieces.append(chunk)\n",
    "            pieces.append(gap)\n",
    "    if pieces:\n",
    "        combined = np.concatenate(pieces)\n",
    "        out_path = out_dir / f\"{PARTICIPANT_ID}_{SPEAKER}_{label_name}.wav\"\n",
    "        write_wav16(out_path, combined, sr)\n",
    "        out_dur = len(combined) / sr\n",
    "        print(f\"  {label_name:6s} â†’ {out_path}  ({out_dur:.1f}s)\")\n",
    "    else:\n",
    "        print(f\"  {label_name:6s} â†’ (no segments)\")\n",
    "\n",
    "print(f\"\\nâœ“ Export complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HindiBabyNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
