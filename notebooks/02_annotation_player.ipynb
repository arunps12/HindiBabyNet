{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27e21cb",
   "metadata": {},
   "source": [
    "# ADS / IDS Annotation Tool\n",
    "\n",
    "**Everything happens here** â€” listen to segments and label them without leaving this notebook.\n",
    "\n",
    "### Workflow\n",
    "1. **Cell 2** â€” Configure participant & speaker  \n",
    "2. **Cell 3** â€” Load audio & detect segments  \n",
    "3. **Cell 4** â€” Annotate: plays each segment, you type `0` / `1` / `2` and press Enter  \n",
    "4. **Cell 5** â€” Export labeled ADS & IDS WAV files\n",
    "\n",
    "### Labels\n",
    "| Input | Label |\n",
    "|-------|-------|\n",
    "| `0` | Other |\n",
    "| `1` | ADS (Adult-Directed Speech) |\n",
    "| `2` | IDS (Infant-Directed Speech) |\n",
    "| `r` | Replay current segment |\n",
    "| `b` | Go back one segment |\n",
    "| `q` | Save & stop (resume later) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PARTICIPANT_ID = \"ABAN141223\"       # â† change this\n",
    "SPEAKER        = \"female\"           # \"female\" or \"male\"\n",
    "\n",
    "# Paths (no need to change)\n",
    "CLASSIFIED_ROOT  = \"/scratch/users/arunps/hindibabynet/audio_classified\"\n",
    "ANNOTATION_ROOT  = \"/scratch/users/arunps/hindibabynet/annotations\"\n",
    "\n",
    "# Segment detection tuning\n",
    "SILENCE_THRESH_DB = -40   # frames below this RMS are silence\n",
    "MIN_SILENCE_SEC   = 0.08  # min silence gap to split on\n",
    "MIN_SEGMENT_SEC   = 0.25  # drop segments shorter than this\n",
    "MAX_SEGMENT_SEC   = 15.0  # split segments longer than this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, wave, time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "LABEL_MAP = {0: \"Other\", 1: \"ADS\", 2: \"IDS\"}\n",
    "\n",
    "# â”€â”€ Read WAV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def read_wav(path):\n",
    "    with wave.open(str(path), \"rb\") as wf:\n",
    "        sr = wf.getframerate()\n",
    "        raw = wf.readframes(wf.getnframes())\n",
    "    return np.frombuffer(raw, dtype=np.int16).astype(np.float32) / 32768.0, sr\n",
    "\n",
    "# â”€â”€ Segment detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def _rms_frames(audio, sr, frame_ms=20):\n",
    "    frame_len = int(sr * frame_ms / 1000)\n",
    "    n = len(audio) // frame_len\n",
    "    if n == 0: return np.array([])\n",
    "    rms = np.sqrt(np.mean(audio[:n*frame_len].reshape(n, frame_len)**2, axis=1) + 1e-12)\n",
    "    return (20 * np.log10(rms + 1e-12)).astype(np.float32)\n",
    "\n",
    "def detect_segments(audio, sr, thresh_db=-40, min_sil=0.08, min_seg=0.25, max_seg=15.0, frame_ms=20):\n",
    "    db = _rms_frames(audio, sr, frame_ms)\n",
    "    if len(db) == 0: return []\n",
    "    frame_len = int(sr * frame_ms / 1000)\n",
    "    is_sil = db < thresh_db\n",
    "    min_sil_f = max(1, int(min_sil * 1000 / frame_ms))\n",
    "\n",
    "    sil_regions = []\n",
    "    in_sil, sil_s = False, 0\n",
    "    for i, s in enumerate(is_sil):\n",
    "        if s and not in_sil: in_sil, sil_s = True, i\n",
    "        elif (not s) and in_sil:\n",
    "            in_sil = False\n",
    "            if i - sil_s >= min_sil_f: sil_regions.append((sil_s, i))\n",
    "    if in_sil and len(is_sil) - sil_s >= min_sil_f:\n",
    "        sil_regions.append((sil_s, len(is_sil)))\n",
    "\n",
    "    total_dur = len(audio) / sr\n",
    "    segs = []\n",
    "    if not sil_regions:\n",
    "        segs.append((0.0, total_dur))\n",
    "    else:\n",
    "        first = sil_regions[0][0] * frame_len / sr\n",
    "        if first > 0: segs.append((0.0, first))\n",
    "        for i in range(len(sil_regions)-1):\n",
    "            s = sil_regions[i][1] * frame_len / sr\n",
    "            e = sil_regions[i+1][0] * frame_len / sr\n",
    "            if e > s: segs.append((s, e))\n",
    "        last = sil_regions[-1][1] * frame_len / sr\n",
    "        if last < total_dur: segs.append((last, total_dur))\n",
    "\n",
    "    segs = [(s, e) for s, e in segs if e - s >= min_seg]\n",
    "\n",
    "    # Split long segments\n",
    "    final = []\n",
    "    for s, e in segs:\n",
    "        if e - s <= max_seg:\n",
    "            final.append((s, e))\n",
    "        else:\n",
    "            final.extend(_split(audio, sr, s, e, max_seg, frame_ms))\n",
    "    return final\n",
    "\n",
    "def _split(audio, sr, start, end, max_s, frame_ms):\n",
    "    if end - start <= max_s: return [(start, end)]\n",
    "    seg = audio[int(start*sr):int(end*sr)]\n",
    "    db = _rms_frames(seg, sr, frame_ms)\n",
    "    if len(db) < 3: return [(start, end)]\n",
    "    n = len(db); lo, hi = n//5, n - n//5\n",
    "    sd = db[lo:hi]\n",
    "    if len(sd) == 0: return [(start, end)]\n",
    "    sp = lo + int(np.argmin(sd))\n",
    "    split_sec = start + sp * int(sr * frame_ms / 1000) / sr\n",
    "    return _split(audio, sr, start, split_sec, max_s, frame_ms) + \\\n",
    "           _split(audio, sr, split_sec, end, max_s, frame_ms)\n",
    "\n",
    "# â”€â”€ CSV persistence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def csv_path(pid, speaker):\n",
    "    return Path(ANNOTATION_ROOT) / pid / f\"{pid}_{speaker}_annotations.csv\"\n",
    "\n",
    "def load_ann(pid, speaker, segments):\n",
    "    p = csv_path(pid, speaker)\n",
    "    if not p.exists(): return {}\n",
    "    ann = {}\n",
    "    with open(p, newline=\"\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            ann[int(row[\"segment_index\"])] = int(row[\"label\"])\n",
    "    return ann\n",
    "\n",
    "def save_ann(pid, speaker, segments, annotations):\n",
    "    p = csv_path(pid, speaker)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(p, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"segment_index\", \"start_sec\", \"end_sec\", \"duration_sec\", \"label\", \"label_name\"])\n",
    "        for idx in sorted(annotations.keys()):\n",
    "            if idx < len(segments):\n",
    "                s, e = segments[idx]\n",
    "                lab = annotations[idx]\n",
    "                w.writerow([idx, f\"{s:.4f}\", f\"{e:.4f}\", f\"{e-s:.4f}\", lab, LABEL_MAP[lab]])\n",
    "    return p\n",
    "\n",
    "# â”€â”€ Load audio & detect segments â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "wav_path = Path(CLASSIFIED_ROOT) / PARTICIPANT_ID / f\"{PARTICIPANT_ID}_main_{SPEAKER}.wav\"\n",
    "assert wav_path.exists(), f\"File not found: {wav_path}\"\n",
    "\n",
    "print(f\"Loading {wav_path.name} ...\")\n",
    "audio, sr = read_wav(wav_path)\n",
    "dur = len(audio) / sr\n",
    "print(f\"Duration: {dur:.1f}s ({dur/60:.1f} min)  |  SR: {sr} Hz\")\n",
    "\n",
    "print(f\"Detecting segments ...\")\n",
    "segments = detect_segments(audio, sr, SILENCE_THRESH_DB, MIN_SILENCE_SEC, MIN_SEGMENT_SEC, MAX_SEGMENT_SEC)\n",
    "durs = [e - s for s, e in segments]\n",
    "print(f\"Found {len(segments)} segments  |  \"\n",
    "      f\"min={min(durs):.2f}s  median={sorted(durs)[len(durs)//2]:.2f}s  max={max(durs):.2f}s\")\n",
    "\n",
    "# Load existing annotations\n",
    "annotations = load_ann(PARTICIPANT_ID, SPEAKER, segments)\n",
    "if annotations:\n",
    "    print(f\"Loaded {len(annotations)} existing annotations (will resume from where you left off)\")\n",
    "print(f\"\\nâœ“ Ready â€” run the next cell to start annotating.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Annotate: listen + label in one loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Re-run this cell to resume from where you left off.\n",
    "\n",
    "total = len(segments)\n",
    "# Find first unannotated segment\n",
    "start_idx = 0\n",
    "unannotated = [i for i in range(total) if i not in annotations]\n",
    "if unannotated:\n",
    "    start_idx = unannotated[0]\n",
    "else:\n",
    "    print(f\"All {total} segments already annotated! Run the export cell below.\")\n",
    "\n",
    "n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "print(f\"Progress: {len(annotations)}/{total} annotated  |  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "print(f\"Starting from segment {start_idx + 1}\\n\")\n",
    "print(\"Labels:  0=Other  1=ADS  2=IDS  |  r=replay  b=back  q=save & stop\\n\")\n",
    "\n",
    "idx = start_idx\n",
    "try:\n",
    "    while 0 <= idx < total:\n",
    "        s, e = segments[idx]\n",
    "        dur_s = e - s\n",
    "        existing = annotations.get(idx)\n",
    "        tag = f\"  [current: {LABEL_MAP[existing]}]\" if existing is not None else \"\"\n",
    "\n",
    "        # Extract segment audio\n",
    "        s_samp = max(0, int(s * sr))\n",
    "        e_samp = min(len(audio), int(e * sr))\n",
    "        chunk = audio[s_samp:e_samp]\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "        n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "        n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "        print(f\"[{idx+1}/{total}]  {s:.2f}s â€“ {e:.2f}s  ({dur_s:.2f}s){tag}\")\n",
    "        print(f\"Progress: {len(annotations)}/{total}  |  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "        print(\"â”€\" * 50)\n",
    "\n",
    "        # Play audio (autoplay in browser)\n",
    "        display(ipd.Audio(chunk, rate=sr, autoplay=True))\n",
    "\n",
    "        while True:\n",
    "            raw = input(\"Label (0/1/2/r/b/q): \").strip().lower()\n",
    "            if raw == \"q\":\n",
    "                save_ann(PARTICIPANT_ID, SPEAKER, segments, annotations)\n",
    "                clear_output(wait=True)\n",
    "                n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "                n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "                n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "                print(f\"âœ“ Saved {len(annotations)}/{total} annotations.  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "                print(f\"  CSV: {csv_path(PARTICIPANT_ID, SPEAKER)}\")\n",
    "                print(f\"  Re-run this cell to resume.\")\n",
    "                raise StopIteration\n",
    "            elif raw == \"r\":\n",
    "                clear_output(wait=True)\n",
    "                print(f\"[{idx+1}/{total}]  {s:.2f}s â€“ {e:.2f}s  ({dur_s:.2f}s)  (replaying...)\")\n",
    "                print(f\"Progress: {len(annotations)}/{total}  |  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "                print(\"â”€\" * 50)\n",
    "                display(ipd.Audio(chunk, rate=sr, autoplay=True))\n",
    "                continue\n",
    "            elif raw == \"b\":\n",
    "                if idx > 0:\n",
    "                    idx -= 1\n",
    "                break\n",
    "            elif raw in (\"0\", \"1\", \"2\"):\n",
    "                annotations[idx] = int(raw)\n",
    "                idx += 1\n",
    "                # Auto-save every 10\n",
    "                if len(annotations) % 10 == 0:\n",
    "                    save_ann(PARTICIPANT_ID, SPEAKER, segments, annotations)\n",
    "                break\n",
    "            else:\n",
    "                print(\"  Invalid. Use 0, 1, 2, r, b, or q.\")\n",
    "\n",
    "    # Finished all segments\n",
    "    save_ann(PARTICIPANT_ID, SPEAKER, segments, annotations)\n",
    "    clear_output(wait=True)\n",
    "    n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "    n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "    n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "    print(f\"ğŸ‰ All {total} segments annotated!  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\")\n",
    "    print(f\"CSV: {csv_path(PARTICIPANT_ID, SPEAKER)}\")\n",
    "    print(f\"Run the export cell below to create separate WAV files.\")\n",
    "\n",
    "except StopIteration:\n",
    "    pass\n",
    "except KeyboardInterrupt:\n",
    "    save_ann(PARTICIPANT_ID, SPEAKER, segments, annotations)\n",
    "    print(f\"\\nInterrupted â€” saved {len(annotations)} annotations. Re-run to resume.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Export: create separate ADS / IDS / Other WAV files â”€â”€â”€â”€â”€â”€\n",
    "# Run this after annotation is complete (or partially complete).\n",
    "\n",
    "def write_wav16(path, data, sr):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pcm = np.clip(data * 32768.0, -32768, 32767).astype(np.int16)\n",
    "    with wave.open(str(path), \"wb\") as wf:\n",
    "        wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(sr)\n",
    "        wf.writeframes(pcm.tobytes())\n",
    "\n",
    "out_dir = Path(ANNOTATION_ROOT) / PARTICIPANT_ID\n",
    "gap = np.zeros(int(sr * 0.15), dtype=np.float32)\n",
    "\n",
    "n_ann = len(annotations)\n",
    "n_ads = sum(1 for v in annotations.values() if v == 1)\n",
    "n_ids = sum(1 for v in annotations.values() if v == 2)\n",
    "n_oth = sum(1 for v in annotations.values() if v == 0)\n",
    "print(f\"Annotations: {n_ann}/{len(segments)}  |  ADS={n_ads}  IDS={n_ids}  Other={n_oth}\\n\")\n",
    "\n",
    "for label_code, label_name in LABEL_MAP.items():\n",
    "    pieces = []\n",
    "    for idx, lab in sorted(annotations.items()):\n",
    "        if lab != label_code or idx >= len(segments): continue\n",
    "        s, e = segments[idx]\n",
    "        chunk = audio[max(0, int(s*sr)):min(len(audio), int(e*sr))]\n",
    "        if len(chunk) > 0:\n",
    "            pieces.append(chunk)\n",
    "            pieces.append(gap)\n",
    "    if pieces:\n",
    "        combined = np.concatenate(pieces)\n",
    "        out_path = out_dir / f\"{PARTICIPANT_ID}_{SPEAKER}_{label_name}.wav\"\n",
    "        write_wav16(out_path, combined, sr)\n",
    "        out_dur = len(combined) / sr\n",
    "        print(f\"  {label_name:6s} â†’ {out_path}  ({out_dur:.1f}s)\")\n",
    "    else:\n",
    "        print(f\"  {label_name:6s} â†’ (no segments)\")\n",
    "\n",
    "print(f\"\\nâœ“ Export complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HindiBabyNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
