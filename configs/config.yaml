artifacts_root: artifacts/runs
logs_root: logs

data_ingestion:
  raw_audio_root: /scratch/users/arunps/hindibabynet/audio_raw
  allowed_ext: [".wav", ".WAV"]
  recordings_filename: recordings.parquet

artifacts_root: artifacts/runs
logs_root: logs

audio_preparation:
  processed_audio_root: /scratch/users/arunps/hindibabynet/audio_processed
  target_sr: 16000
  to_mono: true
  target_peak_dbfs: -1.0
  combine_gap_sec: 0.0

speaker_classification:
  model_path: models/xgb_egemaps.pkl
  class_names: ["adult_male", "adult_female", "child", "background"]
  egemaps_dim: 88
  output_audio_root: /scratch/users/arunps/hindibabynet/audio_classified

  # VAD (webrtcvad)
  vad_aggressiveness: 2
  vad_frame_ms: 30
  vad_min_region_ms: 300

  # Diarization (pyannote)
  diarization_model: "pyannote/speaker-diarization-3.1"
  chunk_sec: 900.0
  overlap_sec: 10.0
  min_speakers: 2
  max_speakers: 4

  # Merge & classify
  # merge_gap_sec: merge same-speaker segments separated by gaps ≤ this value.
  #   0.5  → very fragmented; accurate boundaries but slow on day-long audio
  #   1.0  → good balance for parent–infant day-long recordings (recommended)
  #   1.5  → fewer, longer segments; faster processing; may bridge short pauses
  #   2.0+ → risk merging across actual conversational turn-taking gaps
  merge_gap_sec: 1.0

  # min_segment_sec: discard segments shorter than this value.
  #   0.2  → keeps noisy micro-segments; more false positives
  #   0.3  → drops most artefacts; retains short infant vocalisations (recommended)
  #   0.5  → more reliable features; may lose the shortest babbles/coos
  #   1.0  → only substantial utterances; loses many genuine child sounds
  min_segment_sec: 0.3

  classify_win_sec: 1.0
  classify_hop_sec: 0.5
